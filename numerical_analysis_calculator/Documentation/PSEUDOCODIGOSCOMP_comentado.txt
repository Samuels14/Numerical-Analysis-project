
INCREMENTAL_SEARCH(f, a, b, step):
// Incremental search for sign changes of f(x) on [a,b].
// This routine checks successive intervals of length 'step' and prints intervals where a root is likely.
    x ← a
    f_x ← f(x)
    WHILE x ≤ b DO
        next_x ← x + step
        f_next ← f(next_x)
        // If the function changes sign between x and next_x, a root is in that interval.
        IF f_x * f_next < 0 THEN
            PRINT "Root in interval [", x, ",", next_x, "]"
        END IF
        x ← next_x
        f_x ← f_next
    END WHILE
--------------------------------------------
BISECTION(f, a, b, tol, max_iter):
// Bisection method: reliable root-finding for continuous functions when f(a) and f(b) have opposite signs.
// tol is the tolerance for |f(m)| or interval half-width, max_iter limits iterations.
    fa ← f(a)
    fb ← f(b)
    // If no sign change in the initial interval, the method cannot proceed.
    IF fa * fb > 0 THEN
        PRINT "No root in interval"
        RETURN
    END IF
    FOR k ← 1 TO max_iter DO
        m ← (a + b) / 2
        fm ← f(m)
        PRINT k, a, b, m, fm
        // Stop if function value at midpoint is small or the interval is sufficiently small.
        IF |fm| < tol OR (b - a)/2 < tol THEN
            RETURN m
        END IF
        // Decide which half contains the root by sign change.
        IF fa * fm < 0 THEN
            b ← m
            fb ← fm
        ELSE
            a ← m
            fa ← fm
        END IF
    END FOR
    RETURN m
--------------------------------------------
FALSE_POSITION(f, a, b, tol, max_iter):
// Regula Falsi (False Position): similar to bisection but uses linear interpolation to pick the next point.
// Often converges faster than bisection for some functions, but can be slow if one endpoint stays fixed.
    fa ← f(a)
    fb ← f(b)
    IF fa * fb > 0 THEN
        PRINT "No root in interval"
        RETURN
    END IF
    FOR k ← 1 TO max_iter DO
        // Compute intersection of secant line with x-axis.
        x ← (a*fb - b*fa) / (fb - fa)
        fx ← f(x)
        PRINT k, a, b, x, fx
        IF |fx| < tol THEN
            RETURN x
        END IF
        // Replace the endpoint with the same sign as f(x).
        IF fa * fx < 0 THEN
            b ← x
            fb ← fx
        ELSE
            a ← x
            fa ← fx
        END IF
    END FOR
    RETURN x

--------------------------------------------
FIXED_POINT(g, x0, tol, max_iter):
// Fixed-point iteration: find x such that x = g(x). Convergence depends on g's derivative near the fixed point.
    x ← x0
    FOR k ← 1 TO max_iter DO
        x_next ← g(x)
        err ← |x_next - x|
        PRINT k, x, x_next, err
        // Stop when consecutive iterates are within tolerance.
        IF err < tol THEN
            RETURN x_next
        END IF
        x ← x_next
    END FOR
    RETURN x

--------------------------------------------
NEWTON(f, f', x0, tol, max_iter):
// Newton-Raphson method: uses derivative information for (typically) fast (quadratic) convergence near root.
// Requires f'(x) ≠ 0 near iterates to avoid division by zero.
    x ← x0
    FOR k ← 1 TO max_iter DO
        fx ← f(x)
        fpx ← f'(x)
        IF fpx = 0 THEN
            PRINT "Zero derivative"
            RETURN
        END IF
        // Newton update
        x_next ← x - fx / fpx
        err ← |x_next - x|
        PRINT k, x, fx, fpx, x_next, err
        IF err < tol THEN
            RETURN x_next
        END IF
        x ← x_next
    END FOR
    RETURN x

--------------------------------------------
SECANT(f, x0, x1, tol, max_iter):
// Secant method: approximates derivative by slope between last two iterates; requires two initial guesses.
// Convergence is superlinear but not quadratic.
    FOR k ← 1 TO max_iter DO
        f0 ← f(x0)
        f1 ← f(x1)
        IF f1 - f0 = 0 THEN
            PRINT "Division by zero"
            RETURN
        END IF
        // Secant formula to compute next approximation.
        x2 ← x1 - f1 * (x1 - x0) / (f1 - f0)
        err ← |x2 - x1|
        PRINT k, x0, x1, x2, err
        IF err < tol THEN
            RETURN x2
        END IF
        // Shift iterates
        x0 ← x1
        x1 ← x2
    END FOR
    RETURN x1

--------------------------------------------
MULTIPLE_ROOTS(f, f', x0, m, tol, max_iter):
// Newton method adapted for multiple roots of multiplicity m.
// The correction factor m attempts to restore quadratic convergence when multiplicity is known.
    x ← x0
    FOR k ← 1 TO max_iter DO
        fx ← f(x)
        fpx ← f'(x)
        IF fpx = 0 THEN
            PRINT "Zero derivative"
            RETURN
        END IF
        // Multiply update by m to account for known multiplicity.
        x_next ← x - m * fx / fpx
        err ← |x_next - x|
        PRINT k, x, fx, fpx, x_next, err
        IF err < tol THEN
            RETURN x_next
        END IF
        x ← x_next
    END FOR
    RETURN x

--------------------------------------------
GAUSSIAN_ELIMINATION(A, b, pivot_type):
// Gaussian elimination with optional partial or total pivoting.
// Solves Ax = b by reducing A to upper triangular form, then back substitution.
    n ← number of rows
    FOR k ← 1 TO n-1 DO
        IF pivot_type = 'partial' THEN
            // Partial pivoting: swap current row with row having largest absolute value in column k below or at k.
            swap row with largest |A[i][k]|, i ≥ k
        ELSE IF pivot_type = 'total' THEN
            // Total pivoting: swap rows and columns to place the largest remaining element as pivot.
            swap row & column with largest |A[i][j]|, i,j ≥ k
        END IF
        FOR i ← k+1 TO n DO
            factor ← A[i][k] / A[k][k]
            FOR j ← k TO n DO
                // Eliminate entries below pivot in column k.
                A[i][j] ← A[i][j] - factor * A[k][j]
            END FOR
            // Apply same operations to right-hand-side vector.
            b[i] ← b[i] - factor * b[k]
        END FOR
    END FOR
    // Back substitution to find the solution vector x.
    x[n] ← b[n] / A[n][n]
    FOR i ← n-1 DOWNTO 1 DO
        sum ← b[i]
        FOR j ← i+1 TO n DO
            sum ← sum - A[i][j] * x[j]
        END FOR
        x[i] ← sum / A[i][i]
    END FOR
    RETURN x
--------------------------------------------
FACTORIZACION Y RESOLUCIÓN DE SISTEMAS LINEALES
// Collection of LU and related factorizations for solving linear systems.

1. C11_lusimpl(A, b)
// Simple LU factorization using Gaussian elimination without pivoting.
// Note: This can fail if a zero pivot is encountered or the matrix is singular.
(Factorización LU simple con eliminación gaussiana)
Entrada:
 A: matriz cuadrada
 b: vector de constantes
Salida:
 x: solución del sistema
 L, U: matrices de factorización LU
Pseudocódigo:
n ← número de filas de A
L ← matriz identidad n×n
U ← matriz de ceros n×n
M ← copia de A

// Forward elimination to produce U in M and multipliers in L.
Para i desde 1 hasta n-1 hacer:
    Para j desde i+1 hasta n hacer:
        Si M[j, i] ≠ 0 entonces:
            L[j, i] ← M[j, i] / M[i, i]    // Multiplier saved into L.
            M[j, i:n] ← M[j, i:n] - (M[j, i] / M[i, i]) * M[i, i:n] // Row operation.
        Fin Si
    Fin Para
    U[i, i:n] ← M[i, i:n]               // Copy current row to U.
    U[i+1, i+1:n] ← M[i+1, i+1:n]       // Prepare next diagonal block (keeps U consistent).
Fin Para

U[n, n] ← M[n, n]

z ← sustprgr([L | b]) // Solve Ly = b using forward substitution.
x ← sustregr([U | z]) // Solve Ux = z using back substitution.
Retornar (x, L, U)

________________________________________
2. C12_lupar(A, b)
// LU factorization with partial pivoting (more numerically stable).
// Produces permutation matrix P so that P*A = L*U.
(Factorización LU con pivoteo parcial)
Entrada:
 A: matriz cuadrada
 b: vector de constantes
Salida:
 x: solución
 L, U: matrices LU
 P: matriz de permutación
Pseudocódigo:
n ← número de filas de A
L ← identidad(n)
U ← matriz de ceros(n)
P ← identidad(n)
M ← copia de A

Para i desde 1 hasta n-1 hacer:
    // Find largest absolute value in column i below row i for pivoting.
    (max_val, pos) ← valor y posición del máximo |M[i+1:n, i]|
    Si max_val > |M[i, i]| entonces:
        Intercambiar filas i y i+pos en M y P
        // If L already has multipliers from previous steps, swap the corresponding entries in L.
        Si i > 1 entonces intercambiar las mismas filas en L(,1:i-1)
    Fin Si

    Para j desde i+1 hasta n hacer:
        Si M[j, i] ≠ 0 entonces:
            L[j, i] ← M[j, i] / M[i, i]
            M[j, i:n] ← M[j, i:n] - (M[j, i] / M[i, i]) * M[i, i:n]
        Fin Si
    Fin Para

    U[i, i:n] ← M[i, i:n]
    U[i+1, i+1:n] ← M[i+1, i+1:n]
Fin Para

U[n, n] ← M[n, n]

z ← sustprgr([L | P*b]) // Apply permutation to b, then forward substitution.
x ← sustregr([U | z])
Retornar (x, L, U, P)

________________________________________
3. C13_Crout(A, b)
// Crout LU factorization stores L with non-unit diagonal and U with unit diagonal.
// Useful when you want to compute L and U in-place.
(Factorización LU método Crout)
Pseudocódigo:
n ← tamaño de A
L ← identidad(n)
U ← identidad(n)

Para i desde 1 hasta n-1 hacer:
    Para j desde i hasta n:
        // Compute L column entries for column i.
        L[j, i] ← A[j, i] - Σ_{k=1}^{i-1} L[j, k]*U[k, i]
    Fin Para
    Para j desde i+1 hasta n:
        // Compute U row entries for row i (division by L[i,i]).
        U[i, j] ← (A[i, j] - Σ_{k=1}^{i-1} L[i, k]*U[k, j]) / L[i, i]
    Fin Para
Fin Para

L[n, n] ← A[n, n] - Σ_{k=1}^{n-1} L[n, k]*U[k, n]

z ← sustprgr([L | b])
x ← sustregr([U | z])
Retornar (x, L, U)

________________________________________
4. C14_Doolittle(A, b)
// Doolittle LU factorization: U has full diagonal, L has unit diagonal.
// Another common way to compute LU, often used in textbooks.
(Factorización LU método Doolittle)
Pseudocódigo:
n ← tamaño de A
L ← identidad(n)
U ← identidad(n)

Para i desde 1 hasta n-1 hacer:
    Para j desde i hasta n:
        // Compute U row i.
        U[i, j] ← A[i, j] - Σ_{k=1}^{i-1} L[i, k]*U[k, j]
    Fin Para
    Para j desde i+1 hasta n:
        // Compute L column i (divide by U[i,i]).
        L[j, i] ← (A[j, i] - Σ_{k=1}^{i-1} L[j, k]*U[k, i]) / U[i, i]
    Fin Para
Fin Para

U[n, n] ← A[n, n] - Σ_{k=1}^{n-1} L[n, k]*U[k, n]

z ← sustprgr([L | b])
x ← sustregr([U | z])
Retornar (x, L, U)

________________________________________
5. C15_Cholesky(A, b)
// Cholesky factorization for symmetric positive-definite matrices: A = L * L^T.
// It is more efficient and numerically stable for this matrix class.
(Factorización Cholesky)
Pseudocódigo:
n ← tamaño de A
L ← identidad(n)
U ← identidad(n)

Para i desde 1 hasta n-1 hacer:
    // Compute diagonal element of L as the square root of the Schur complement.
    L[i, i] ← √(A[i, i] - Σ_{k=1}^{i-1} L[i, k]*U[k, i])
    U[i, i] ← L[i, i]   // For Cholesky, U is the transpose of L, so diagonal entries are equal.
    Para j desde i+1 hasta n:
        // Compute lower column entries and corresponding upper row entries.
        L[j, i] ← (A[j, i] - Σ_{k=1}^{i-1} L[j, k]*U[k, i]) / U[i, i]
        U[i, j] ← (A[i, j] - Σ_{k=1}^{i-1} L[i, k]*U[k, j]) / L[i, i]
    Fin Para
Fin Para

L[n, n] ← √(A[n, n] - Σ_{k=1}^{n-1} L[n, k]*U[k, n])
U[n, n] ← L[n, n]

z ← sustprgr([L | b]) // Solve Ly = b.
x ← sustregr([U | z]) // Solve L^T x = y (U is L^T here).
Retornar (x, L, U)

________________________________________
6. C16_jacobi(A, b, x0, tol, Nmax)
// Jacobi iterative method: solves Ax = b by splitting A = D - (L + U) where D is diagonal.
// Convergence requires the spectral radius of iteration matrix T to be < 1 (e.g., diagonally dominant matrices).
(Método de Jacobi)
Entrada:
 A: matriz cuadrada
 b: vector constante
 x0: vector inicial
 tol: tolerancia
 Nmax: número máximo de iteraciones
Salida:
 x: aproximación de la solución
 iter: número de iteraciones realizadas
 err: error final
Pseudocódigo:
D ← diag(diag(A))          // Diagonal matrix of A.
L ← -tril(A) + D           // Strict lower part with sign change so that A = D - L - U convention fits.
U ← -triu(A) + D           // Strict upper part with sign change.
T ← inv(D) * (L + U)       // Iteration matrix.
C ← inv(D) * b             // Constant term.
xant ← x0
E ← 1000
cont ← 0

Mientras (E > tol) y (cont < Nmax) hacer:
    xact ← T * xant + C    // Update using iteration matrix.
    E ← ||xant - xact||    // Norm of difference as error measure.
    xant ← xact
    cont ← cont + 1
Fin Mientras

x ← xact
iter ← cont
err ← E
Retornar (x, iter, err)

________________________________________
7. C17_gseidel(A, b, x0, tol, Nmax)
// Gauss-Seidel method: uses new component values immediately within iteration which often speeds convergence.
(Método de Gauss-Seidel)
Pseudocódigo:
D ← diag(diag(A))
L ← -tril(A) + D
U ← -triu(A) + D
T ← inv(D - L) * U   // Iteration matrix for Gauss-Seidel.
C ← inv(D - L) * b
xant ← x0
E ← 1000
cont ← 0

Mientras (E > tol) y (cont < Nmax) hacer:
    xact ← T * xant + C
    E ← ||xant - xact||
    xant ← xact
    cont ← cont + 1
Fin Mientras

x ← xact
iter ← cont
err ← E
Retornar (x, iter, err)

________________________________________
8. C18_sor(A, b, x0, w, tol, Nmax)
// Successive Over-Relaxation (SOR): introduces relaxation parameter w to potentially accelerate Gauss-Seidel.
// Optimal w depends on matrix A; w in (0,2) and typically 1 < w < 2 for over-relaxation.
(Método SOR – Successive Over-Relaxation)
Pseudocódigo:
D ← diag(diag(A))
L ← -tril(A) + D
U ← -triu(A) + D
T ← inv(D - w*L) * ((1 - w)*D + w*U) // Iteration matrix depends on w.
C ← w * inv(D - w*L) * b
xant ← x0
E ← 1000
cont ← 0

Mientras (E > tol) y (cont < Nmax) hacer:
    xact ← T * xant + C
    E ← ||xant - xact||
    xant ← xact
    cont ← cont + 1
Fin Mientras

x ← xact
iter ← cont
err ← E
Retornar (x, iter, err)

________________________________________
9. C19_vandermonde(X, Y)
// Compute polynomial interpolation coefficients by solving the Vandermonde system.
// Vandermonde matrices can be ill-conditioned for large n; use with care.
(Vandermonde interpolation)
Pseudocódigo:
n ← longitud(X)
A ← matriz de ceros n×n

Para i desde 1 hasta n hacer:
    A[:, i] ← X^(n - i) // Fill columns with powers of X, highest power first.
Fin Para

Coef ← resolver(A, Y) // Solve A * Coef = Y for polynomial coefficients.
Retornar Coef

________________________________________
10. C20_difdivididas(X, Y)
// Newton's divided differences to compute polynomial in Newton form.
// Produces coefficients easily used for incremental polynomial evaluation.
(Interpolación de Newton – diferencias divididas)
Pseudocódigo:
n ← longitud(X)
D ← matriz de ceros n×n
D[:,1] ← Y

Para i desde 2 hasta n hacer:
    Para j desde i hasta n hacer:
        D[j, i] ← (D[j, i-1] - D[j-1, i-1]) / (X[j] - X[j-i+1])
        // Each column i stores i-th order divided differences.
    Fin Para
Fin Para

Coef ← diagonal(D) // The Newton coefficients are the diagonal of D.
Retornar Coef

________________________________________
11. C21_lagrange(X, Y)
// Lagrange interpolation: constructs basis polynomials L_i(x) and combines them with Y to get coefficients.
// The algorithm here builds polynomial coefficients via polynomial multiplication (convolution).
(Interpolación por el método de Lagrange)
Pseudocódigo:
n ← longitud(X)
L ← matriz de ceros n×n

Para i desde 1 hasta n hacer:
    aux0 ← X sin X[i]            // Likely means create vector of (X - X[i]) terms; original text uses 'sin' but intention is (X - X[i]).
    aux ← [1, -aux0[1]]         // Start polynomial (x - X[i]) represented as coefficients [1, -X[i]].
    Para j desde 2 hasta n-1 hacer:
        aux ← conv(aux, [1, -aux0[j]])    // Multiply polynomials to get basis polynomial numerator.
    Fin Para
    L[i, :] ← aux / evaluar(aux, X[i])   // Normalize so that L_i(X[i]) = 1.
Fin Para

Coef ← Y * L // Combine basis polynomials with y-values to obtain final polynomial coefficients.
Retornar (L, Coef)

________________________________________
12. C22_trazlin(X, Y)
// Linear spline interpolation: piecewise linear segments between data points.
(Linear spline)
Pseudocódigo:
n ← longitud(X)
m ← 2*(n-1)
A ← matriz de ceros m×m
b ← vector de ceros m
Coef ← matriz de ceros (n-1)×2

// Interpolation conditions: each segment matches data at end points.
Para i desde 1 hasta n-1 hacer:
    A[i+1, (2*i-1):(2*i)] ← [X[i+1], 1]
    b[i+1] ← Y[i+1]
Fin Para
A[1, 1:2] ← [X[1], 1]
b[1] ← Y[1]

// Continuity conditions at interior nodes: value from left segment equals value from right segment.
Para i desde 2 hasta n-1 hacer:
    A[n-1+i, (2*i-3):(2*i)] ← [X[i], 1, -X[i], -1]
    b[n-1+i] ← 0
Fin Para

Saux ← resolver(A, b)
Para i desde 1 hasta n-1 hacer:
    Coef[i, :] ← Saux[(2*i-1):(2*i)]
Fin Para
Retornar Coef

________________________________________
13. C23_trazcuad(X, Y)
// Quadratic spline interpolation with continuity and smoothness conditions.
// Forms a global linear system for coefficients of each quadratic polynomial.
(Spline cuadrático)
Pseudocódigo:
n ← longitud(X)
m ← 3*(n-1)
A ← ceros(m, m)
b ← ceros(m)
Coef ← ceros(n-1, 3)

// Interpolation conditions
Para i desde 1 hasta n-1 hacer:
    A[i+1, (3*i-2):(3*i)] ← [X[i+1]^2, X[i+1], 1]
    b[i+1] ← Y[i+1]
Fin Para
A[1, 1:3] ← [X[1]^2, X[1], 1]
b[1] ← Y[1]

// Continuity of value at interior nodes
Para i desde 2 hasta n-1 hacer:
    A[n-1+i, (3*i-5):(3*i)] ← [X[i]^2, X[i], 1, -X[i]^2, -X[i], -1]
Fin Para

// Smoothness: continuity of first derivative at interior nodes
Para i desde 2 hasta n-1 hacer:
    A[2*n-3+i, (3*i-5):(3*i)] ← [2*X[i], 1, 0, -2*X[i], -1, 0]
Fin Para

// Boundary condition (example): second derivative zero at first node (or similar).
A[m, 1] ← 2
b[m] ← 0

Saux ← resolver(A, b)
Para i desde 1 hasta n-1 hacer:
    Coef[i, :] ← Saux[(3*i-2):(3*i)]
Fin Para
Retornar Coef

________________________________________
14. C24_trazcub(X, Y)
// Cubic spline interpolation: enforces value, first and second derivative continuity, and natural boundary conditions.
(Spline cúbico)
Pseudocódigo:
n ← longitud(X)
m ← 4*(n-1)
A ← ceros(m, m)
b ← ceros(m)
Coef ← ceros(n-1, 4)

// Interpolation conditions
Para i desde 1 hasta n-1 hacer:
    A[i+1, (4*i-3):(4*i)] ← [X[i+1]^3, X[i+1]^2, X[i+1], 1]
    b[i+1] ← Y[i+1]
Fin Para
A[1, 1:4] ← [X[1]^3, X[1]^2, X[1], 1]
b[1] ← Y[1]

// Continuity of value at interior nodes
Para i desde 2 hasta n-1 hacer:
    A[n-1+i, (4*i-7):(4*i)] ← [X[i]^3, X[i]^2, X[i], 1, -X[i]^3, -X[i]^2, -X[i], -1]
Fin Para

// Continuity of first derivative
Para i desde 2 hasta n-1 hacer:
    A[2*n-3+i, (4*i-7):(4*i)] ← [3*X[i]^2, 2*X[i], 1, 0, -3*X[i]^2, -2*X[i], -1, 0]
Fin Para

// Continuity of second derivative
Para i desde 2 hasta n-1 hacer:
    A[3*n-5+i, (4*i-7):(4*i)] ← [6*X[i], 2, 0, 0, -6*X[i], -2, 0, 0]
Fin Para

// Natural boundary conditions: second derivative zero at endpoints.
A[m-1, 1:2] ← [6*X[1], 2]
A[m, m-3:m-2] ← [6*X[n], 2]
b[m-1] ← 0
b[m] ← 0

Saux ← resolver(A, b)
Para i desde 1 hasta n-1 hacer:
    Coef[i, :] ← Saux[(4*i-3):(4*i)]
Fin Para
Retornar Coef.

------------------------------------

// AUXILIARY ROUTINES FOR SUBSTITUTION
// These are helper procedures used by many factorization routines.

1. sustregr(M)
// Back substitution for augmented matrix [U | b], where U is upper triangular.
// Computes solution x from last row up to first.
(Sustitución regresiva para matriz aumentada [U|b])
Entrada:
 M = matriz aumentada [U|b], con U triangular superior.
Salida:
 x = vector solución.
Pseudocódigo:
n ← número de filas de M
x ← vector de ceros de tamaño n

x[n] ← M[n, n+1] / M[n, n] // Last variable solved directly.

Para i desde n-1 hasta 1 hacer:
    aux ← [1, x[i+1 ... n]]               // Build vector [1, x_{i+1}, ..., x_n] for dot product.
    aux1 ← [M[i, n+1], -M[i, i+1 ... n]] // Right-hand side and negated coefficients for dot product.
    // Compute x[i] using dot product trick: (1 * b_i + sum(-A[i,j]*x[j])) / A[i,i]
    x[i] ← (aux ⋅ aux1) / M[i, i]
Fin Para

Retornar x

________________________________________
2. sustprgr(M)
// Forward substitution for augmented matrix [L | b], where L is lower triangular.
// Computes solution x by starting from first equation downwards.
(Sustitución progresiva para matriz aumentada [L|b])
Entrada:
 M = matriz aumentada [L|b], con L triangular inferior.
Salida:
 x = vector solución.
Pseudocódigo:
n ← número de filas de M
x ← vector de ceros de tamaño n

x[1] ← M[1, n+1] / M[1, 1] // Solve first variable.

Para i desde 2 hasta n hacer:
    aux ← [1, x[1 ... i-1]]               // [1, x1, x2, ..., x_{i-1}]
    aux1 ← [M[i, n+1], -M[i, 1 ... i-1]] // b_i and negated known coefficients.
    // Compute x[i] similarly using dot product.
    x[i] ← (aux ⋅ aux1) / M[i, i]
Fin Para

Retornar x

// End of commented pseudocode file.
